{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\nimport torch\n\nmodel_name = \"5CD-AI/Vintern-1B-v3_5\"\n\nmodel = AutoModel.from_pretrained(\n  model_name,\n  torch_dtype=torch.bfloat16,\n  low_cpu_mem_usage=True,\n  trust_remote_code=True,\n  use_flash_attn=False,\n).cuda()\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, use_fast=False, padding='right')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:57:14.743989Z","iopub.execute_input":"2025-05-22T18:57:14.744225Z","iopub.status.idle":"2025-05-22T18:58:21.186964Z","shell.execute_reply.started":"2025-05-22T18:57:14.744202Z","shell.execute_reply":"2025-05-22T18:58:21.186089Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/5.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"098002aa6306492b845d70ee882f2b24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_internvl_chat.py:   0%|          | 0.00/3.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b61b788391f84becbe594c9051348131"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_intern_vit.py:   0%|          | 0.00/5.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f0f3b23bb17489a933a555f3837ffd9"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/5CD-AI/Vintern-1B-v3_5:\n- configuration_intern_vit.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/5CD-AI/Vintern-1B-v3_5:\n- configuration_internvl_chat.py\n- configuration_intern_vit.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_internvl_chat.py:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"682ce3aef6d041bf95dfdd728ad27c37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conversation.py:   0%|          | 0.00/16.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a8b4443f49c487aa0570f54d20231b1"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/5CD-AI/Vintern-1B-v3_5:\n- conversation.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_intern_vit.py:   0%|          | 0.00/18.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d833e5646534b81870778b88cb4103e"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/5CD-AI/Vintern-1B-v3_5:\n- modeling_intern_vit.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/5CD-AI/Vintern-1B-v3_5:\n- modeling_internvl_chat.py\n- conversation.py\n- modeling_intern_vit.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n2025-05-22 18:57:44.332230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747940264.794193      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747940264.914714      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"FlashAttention2 is not installed.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.75G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"375854aa7ff4443aaaf8f838a9f1e2af"}},"metadata":{}},{"name":"stderr","text":"Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/129 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53692563ff9448678be7e68e1264c08c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/9.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d46e9aa4a84a4eb18fa15e3e70834ef8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/3.38M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f006622dd82645178157d281ff7c2b22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f692117cdde4bd3925fe7c0a335abdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/790 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd9b8de07d9346f4bbab084a235b85f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/744 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c06a8aa5cfb443338ad043dc8e15f0cc"}},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('5CD-AI/Vietnamese-Multi-turn-Chat-Alpaca')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:21:21.451732Z","iopub.execute_input":"2025-05-22T19:21:21.452064Z","iopub.status.idle":"2025-05-22T19:21:22.531347Z","shell.execute_reply.started":"2025-05-22T19:21:21.452046Z","shell.execute_reply":"2025-05-22T19:21:22.530824Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def prepare_dataset(sample):\n    processed_sample = []\n    for turn in sample['conversations']:\n        processed_turn = {}\n        if turn['from'] == 'human':\n            processed_turn['role'] = 'user'\n        elif turn['from'] == 'gpt':\n            processed_turn['role'] = 'assistant'\n        processed_turn['content'] = turn['value']\n        processed_sample.append(processed_turn)\n    return {'conversations':processed_sample}\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:21:23.673045Z","iopub.execute_input":"2025-05-22T19:21:23.673605Z","iopub.status.idle":"2025-05-22T19:21:23.677939Z","shell.execute_reply.started":"2025-05-22T19:21:23.673560Z","shell.execute_reply":"2025-05-22T19:21:23.677279Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Apply dataset preparation\nprint(\"Preparing dataset...\")\ndataset = dataset['train'].map(prepare_dataset, remove_columns=['conversations', 'id'], num_proc=4)\nprint(f\"Processed dataset sample: {dataset[0]['conversations']}\")\n\n# Apply chat template (no pixel_values here)\nprint(\"Applying chat template...\")\ndataset = dataset.map(lambda x: {'text': tokenizer.apply_chat_template(x['conversations'], tokenize=False)}, num_proc=4)\nprint(f\"Formatted sample: {dataset[0]['text'][:200]}...\")\n\n# Tokenize dataset\ndef tokenize_function(example):\n    tokenized = tokenizer(example['text'], padding='longest', truncation=True, max_length=512)\n    # Store image_flags as a scalar (not tensor yet, to avoid pin_memory issue)\n    tokenized['image_flags'] = 0  # Scalar integer for text-only\n    return tokenized\n\nprint(\"Tokenizing dataset...\")\ntokenized_dataset = dataset.map(tokenize_function, batched=False, remove_columns=['conversations', 'text'], load_from_cache_file=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:21:24.668893Z","iopub.execute_input":"2025-05-22T19:21:24.669175Z","iopub.status.idle":"2025-05-22T19:22:48.658367Z","shell.execute_reply.started":"2025-05-22T19:21:24.669155Z","shell.execute_reply":"2025-05-22T19:22:48.657654Z"}},"outputs":[{"name":"stdout","text":"Preparing dataset...\nProcessed dataset sample: [{'content': 'Hãy chỉnh sửa câu này để ngắn gọn hơn mà không mất đi ý nghĩa: \"Trận đấu là một thất bại nặng nề mặc dù thực tế là cả đội đã tập luyện trong nhiều tuần.\"', 'role': 'user'}, {'content': 'Nhiều tuần huấn luyện của đội đã dẫn đến một thất bại nặng nề.', 'role': 'assistant'}, {'content': 'Bạn có thể đề xuất một số chiến lược mà nhóm có thể sử dụng để cải thiện hiệu suất của họ trong trận đấu tiếp theo không?', 'role': 'user'}, {'content': 'Chắc chắn, đây là một số chiến lược mà nhóm có thể sử dụng để cải thiện hiệu suất của mình trong trận đấu tiếp theo: 1. Phân tích trận đấu trước bằng cách xem lại cảnh quay trận đấu để xác định điểm yếu và các lĩnh vực cần cải thiện. 2. Tăng cường độ và sự tập trung của các buổi tập để đảm bảo mọi cầu thủ đều được chuẩn bị đầy đủ về thể chất và tinh thần. 3. Luyện tập những kỹ năng cụ thể cần cải thiện, chẳng hạn như sút bóng hoặc chuyền bóng chính xác. 4. Phát triển các chiến lược và chiến thuật của đội có tính đến điểm mạnh và điểm yếu của cả đội bạn và đối thủ. 5. Xây dựng sự gắn kết và giao tiếp trong nhóm để cải thiện sự cộng tác và làm việc nhóm trên thực địa. 6. Phát triển tinh thần dẻo dai và khả năng phục hồi để vượt qua thất bại và duy trì sự tập trung trong các tình huống áp lực cao. 7. Tăng cường thể chất để cải thiện sức bền và giảm mệt mỏi khi chơi game. 8. Nghỉ ngơi và phục hồi - đảm bảo rằng các cầu thủ được nghỉ ngơi đầy đủ và dinh dưỡng đầy đủ trước trận đấu để đảm bảo mọi người đều ở trạng thái tốt nhất.', 'role': 'assistant'}, {'content': 'Cảm ơn những lời đề nghị. Bạn nghĩ chiến lược nào sẽ có tác động đáng kể nhất đến hiệu suất của nhóm?', 'role': 'user'}, {'content': 'Là một mô hình ngôn ngữ AI, tôi không thể dự đoán chiến lược nào sẽ có tác động đáng kể nhất đến hiệu suất của nhóm vì mỗi nhóm là duy nhất và có thể yêu cầu các cách tiếp cận khác nhau để cải thiện hiệu suất của họ. Tuy nhiên, tôi có thể đề xuất rằng đội nên ưu tiên các chiến lược giải quyết những điểm yếu nhất của họ, đảm bảo rằng các cầu thủ của họ ở trạng thái thể chất và tinh thần tốt nhất, đồng thời xây dựng tinh thần đồng đội gắn kết để tận dụng tối đa mọi cầu thủ.', 'role': 'assistant'}, {'content': 'Đó là một điểm tuyệt vời. Làm thế nào đội có thể cải thiện khả năng giao tiếp trên sân?', 'role': 'user'}, {'content': 'Cải thiện giao tiếp trên thực địa là rất quan trọng để xây dựng một nhóm hiệu quả có thể làm việc cùng nhau và đạt được thành công. Dưới đây là một số chiến lược mà nhóm có thể sử dụng để cải thiện khả năng giao tiếp của họ trên hiện trường: 1. Thiết lập các giao thức liên lạc rõ ràng - thiết lập các tín hiệu và mã rõ ràng để mọi người trên hiện trường hiểu ý nghĩa của từng tín hiệu. 2. Khuyến khích giao tiếp cởi mở - người chơi nên được khuyến khích giao tiếp với nhau một cách tự do và cởi mở, không sợ bị chỉ trích hay bị trừng phạt. 3. Lặp lại thông tin chính - thông tin quan trọng, chẳng hạn như vị trí của người chơi, nên được lặp lại nhiều lần để đảm bảo rằng mọi người đều hiểu được. 4. Phát triển niềm tin - Người chơi nên tin tưởng lẫn nhau để đưa ra quyết định đúng đắn và giao tiếp hiệu quả, điều này sẽ giảm bớt sự nhầm lẫn và hiểu lầm trong quá trình chơi game. 5. Sử dụng ngôn ngữ tích cực - Ngôn ngữ tích cực có thể giúp thúc đẩy một môi trường hợp tác, hỗ trợ, khuyến khích giao tiếp và làm việc theo nhóm. 6. Thực hành giao tiếp trong quá trình tập luyện - Giao tiếp nên là một phần của các buổi tập luyện thường xuyên, để các cầu thủ quen với việc giao tiếp với nhau trong các trận đấu. Bằng cách tuân theo các chiến lược này, nhóm có thể cải thiện khả năng giao tiếp trên thực địa và làm việc cùng nhau hiệu quả hơn để đạt được mục tiêu của mình.', 'role': 'assistant'}, {'content': 'Cảm ơn đã phản ứng chi tiết. Làm thế nào nhóm có thể theo dõi tiến trình của họ và đảm bảo rằng họ đang cải thiện theo thời gian?', 'role': 'user'}, {'content': 'Đo lường tiến độ và phân tích kết quả có thể giúp nhóm đi đúng hướng và thực hiện các điều chỉnh để cải thiện hiệu suất của họ. Dưới đây là một số cách mà nhóm có thể theo dõi tiến trình của mình theo thời gian: 1. Đặt ra các mục tiêu cụ thể cần đạt được - việc có những mục tiêu rõ ràng và có thể đo lường được mà mọi người trong nhóm đều hiểu có thể giúp họ luôn có động lực và tập trung. 2. Thu thập dữ liệu và số liệu thống kê - dữ liệu có thể cung cấp phản hồi có giá trị về hiệu suất của đội, chẳng hạn như số bàn thắng ghi được, đường kiến \\u200b\\u200btạo và số cú sút trúng đích. 3. Sử dụng đánh giá của người chơi - đánh giá hiệu suất định kỳ có thể giúp xác định các lĩnh vực cần cải thiện và các lĩnh vực đang hoạt động tốt. 4. Phân tích cảnh quay trò chơi - sử dụng cảnh quay trò chơi để phân tích chuyển động, kiểu mẫu và giao tiếp của người chơi, nhóm có thể xác định các lĩnh vực cần cải thiện. 5. Theo dõi mức độ thể lực - theo dõi mức độ thể lực theo thời gian có thể giúp nhóm theo dõi sự cải thiện về thể lực, điều này có thể dẫn đến hiệu suất tốt hơn trên sân. 6. Kết hợp phản hồi từ huấn luyện viên và đồng đội - phản hồi từ huấn luyện viên và đồng đội có thể cung cấp những hiểu biết sâu sắc và ý tưởng có giá trị giúp cải thiện hiệu suất. Bằng cách liên tục theo dõi tiến trình của họ, nhóm có thể đảm bảo rằng họ đang tiến bộ theo thời gian và thực hiện các điều chỉnh về chiến lược cũng như đào tạo nếu cần thiết.', 'role': 'assistant'}]\nApplying chat template...\nFormatted sample: <|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nHãy chỉnh sửa câu này để ngắn gọn hơn mà không mất đi ý nghĩa: \"Trận đấu là một thất ...\nTokenizing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12697 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"704f7ebf3c84402daa85796766f0cb6c"}},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\n# Custom data collator to add dummy pixel_values\nclass CustomDataCollator(DataCollatorForLanguageModeling):\n    def __call__(self, examples):\n        batch = super().__call__(examples)\n        batch_size = len(examples)\n        # Add dummy pixel_values for the batch (shared tensor to save memory)\n        batch['pixel_values'] = torch.zeros((batch_size, 3, 3, 448, 448), dtype=torch.float16).to(\"cuda\")\n        batch['image_flags'] = torch.tensor([ex['image_flags'] for ex in examples], dtype=torch.long).to(\"cuda\")\n        return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:44:33.142501Z","iopub.execute_input":"2025-05-22T19:44:33.143200Z","iopub.status.idle":"2025-05-22T19:44:33.147995Z","shell.execute_reply.started":"2025-05-22T19:44:33.143177Z","shell.execute_reply":"2025-05-22T19:44:33.147366Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nimport os\n\n# Disable W&B to avoid hangs\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./qwen2_finetuned\",\n    per_device_train_batch_size=1,  # Minimize memory usage\n    gradient_accumulation_steps=8,  # Effective batch size = 8\n    learning_rate=2e-5,\n    num_train_epochs=1,  # Start with 1 epoch\n    logging_steps=1,  # Log every step\n    logging_dir=\"./logs\",\n    fp16=True,  # Mixed precision\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    report_to=\"none\",  # Disable all logging integrations\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    data_collator=CustomDataCollator(tokenizer=tokenizer, mlm=False),\n)\n\n# Start fine-tuning\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T19:44:34.245874Z","iopub.execute_input":"2025-05-22T19:44:34.246358Z","iopub.status.idle":"2025-05-22T19:44:34.759886Z","shell.execute_reply.started":"2025-05-22T19:44:34.246337Z","shell.execute_reply":"2025-05-22T19:44:34.758902Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/454471365.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Start fine-tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2512\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2514\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2515\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5242\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5243\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5244\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5245\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 clone.update(\n\u001b[0;32m---> 75\u001b[0;31m                     \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 )\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 clone.update(\n\u001b[0;32m---> 75\u001b[0;31m                     \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 )\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: cannot pin 'torch.cuda.LongTensor' only dense CPU tensors can be pinned"],"ename":"RuntimeError","evalue":"cannot pin 'torch.cuda.LongTensor' only dense CPU tensors can be pinned","output_type":"error"}],"execution_count":35},{"cell_type":"code","source":"help(model.forward)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T04:28:16.181340Z","iopub.execute_input":"2025-05-22T04:28:16.181630Z","iopub.status.idle":"2025-05-22T04:28:16.186680Z","shell.execute_reply.started":"2025-05-22T04:28:16.181611Z","shell.execute_reply":"2025-05-22T04:28:16.185702Z"}},"outputs":[{"name":"stdout","text":"Help on method forward in module transformers_modules.5CD-AI.Vintern-1B-v3_5.115975aca0407d3c54bb0beb8a1da54d31de3f20.modeling_internvl_chat:\n\nforward(pixel_values: torch.FloatTensor, input_ids: torch.LongTensor = None, attention_mask: Optional[torch.Tensor] = None, position_ids: Optional[torch.LongTensor] = None, image_flags: Optional[torch.LongTensor] = None, past_key_values: Optional[List[torch.FloatTensor]] = None, labels: Optional[torch.LongTensor] = None, use_cache: Optional[bool] = None, output_attentions: Optional[bool] = None, output_hidden_states: Optional[bool] = None, return_dict: Optional[bool] = None) -> Union[Tuple, transformers.modeling_outputs.CausalLMOutputWithPast] method of transformers_modules.5CD-AI.Vintern-1B-v3_5.115975aca0407d3c54bb0beb8a1da54d31de3f20.modeling_internvl_chat.InternVLChatModel instance\n    Define the computation performed at every call.\n    \n    Should be overridden by all subclasses.\n    \n    .. note::\n        Although the recipe for forward pass needs to be defined within\n        this function, one should call the :class:`Module` instance afterwards\n        instead of this since the former takes care of running the\n        registered hooks while the latter silently ignores them.\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}